{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.magic import register_line_magic\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from torch import nn, optim\n",
    "    import torch.nn.functional as F\n",
    "    from torch.autograd import Variable\n",
    "    import torchvision\n",
    "    import torchvision.transforms as transforms\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"No pytorch package is found. Please install it.\")\n",
    "\n",
    "try:\n",
    "    from ignite.engines import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "    from ignite.metrics import CategoricalAccuracy, Loss\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"No ignite package is found. Please install by following the instructions at: https://github.com/pytorch/ignite\")\n",
    "\n",
    "try:\n",
    "    import visdom\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"No visdom package is found. Please install it with command: \\n pip install visdom\")\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import gc\n",
    "import shutil\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: code has not been tested in a non-cuda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_CLASSES = ('0', '1', '2', '3', '4', '5', '6' ,'7', '8', '9')\n",
    "\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "BATCH_SIZE_TEST = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@register_line_magic\n",
    "def pip(args):\n",
    "    \"\"\"Use pip from the current kernel\"\"\"\n",
    "    from pip import main\n",
    "    main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeights(in_channels, out_channels, kernel_size, sparsity):\n",
    "    W_size = torch.Size([out_channels,in_channels,kernel_size,kernel_size]) \n",
    "    W = torch.sparse.FloatTensor(W_size)\n",
    "    uniform = torch.FloatTensor(W_size).fill_(0.5)\n",
    "    W = torch.bernoulli(uniform) * 2 - 1\n",
    "    rand = torch.rand(W_size)\n",
    "    mask = rand > sparsity\n",
    "\n",
    "    W.masked_fill_(mask, 0)\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "class LBCFilter(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, sparsity, W = None):\n",
    "        super(LBCFilter, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.ConvModule = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1, bias=False)\n",
    "        if (W is None):\n",
    "            W = getWeights(in_channels, out_channels, kernel_size, sparsity)\n",
    "        \n",
    "        self.ConvModule.weight = nn.Parameter(W, requires_grad=False)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.ConvModule.forward(x)\n",
    "        \n",
    "\n",
    "\n",
    "class LBCBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_size=3, sparsity=0.9, W = None):\n",
    "        super(LBCBlock, self).__init__()\n",
    "        self.Batch_Norm = nn.BatchNorm2d(in_channels)\n",
    "        self.LBCModule = LBCFilter(in_channels, out_channels, 3, sparsity, W)\n",
    "        self.Conv2d = nn.Conv2d(out_channels, in_channels, kernel_size=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        residual = x\n",
    "        \n",
    "        out = self.Batch_Norm(x)\n",
    "        out = F.relu(self.LBCModule(out))\n",
    "        out = self.Conv2d(out)\n",
    "        \n",
    "        out += residual\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class LBCBlock_DENSE(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_size=3, sparsity=0.9):\n",
    "        super(LBCBlock_DENSE, self).__init__()\n",
    "        \n",
    "        self.Batch_Norm = nn.BatchNorm2d(in_channels)\n",
    "        self.LBCModule = nn.Conv2d(in_channels, out_channels,kernel_size=(3,3),padding=1, bias=False)\n",
    "        self.Conv2d = nn.Conv2d(out_channels, in_channels, kernel_size=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        residual = x\n",
    "        \n",
    "        out = self.Batch_Norm(x)\n",
    "        out = F.relu(self.LBCModule(out))\n",
    "        out = self.Conv2d(out)\n",
    "        \n",
    "        out += residual\n",
    "    \n",
    "        return x" #think you meant "return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet_MNIST(nn.Module):\n",
    "    def __init__(self, in_channels, out_features, depth, dense, sparsity=0.1, shared = False):\n",
    "        super(ResNet_MNIST, self).__init__()\n",
    "        self.PreprocBlock = nn.Sequential(\n",
    "            nn.Conv2d(1, in_channels, kernel_size=3,padding=2),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        if (shared):\n",
    "            W = getWeightMatrix(in_channels, out_features, 3, sparsity)\n",
    "            self.LBCChain = nn.Sequential(*[LBCBlock(in_channels, out_features, 3, sparsity, W) for layer in range(depth)])\n",
    "            \n",
    "        else:\n",
    "            self.LBCChain = nn.Sequential(*[LBCBlock(in_channels, out_features, 3, sparsity) for layer in range(depth)])\n",
    "        \n",
    "        self.AvgPooling = nn.AvgPool2d(5,5)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten_size = in_channels * 6 * 6\n",
    "        self.dense = nn.Linear(self.flatten_size, dense)\n",
    "        self.out = nn.Linear(dense, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.PreprocBlock(x)\n",
    "        x = self.LBCChain(x)\n",
    "        x = self.AvgPooling(x)\n",
    "        \n",
    "        x = x.view(-1, self.flatten_size)        \n",
    "        \n",
    "        x = self.dense(self.dropout(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        t = self.out(x)\n",
    "        \n",
    "        return t\n",
    "    \n",
    "    \n",
    "class ResNet_MNIST_DENSE(nn.Module):\n",
    "    def __init__(self, in_channels, out_features, depth, dense, sparsity=0.1):\n",
    "        super(ResNet_MNIST_DENSE, self).__init__()\n",
    "        \n",
    "        self.PreprocBlock = nn.Sequential(\n",
    "            nn.Conv2d(1, in_channels, kernel_size=3,padding=2),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.LBCChain = nn.Sequential(*[LBCBlock_DENSE(in_channels, out_features, sparsity) for layer in range(depth)])\n",
    "        self.AvgPooling = nn.AvgPool2d(5,5)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten_size = in_channels * 6 * 6\n",
    "        self.dense = nn.Linear(self.flatten_size, dense)\n",
    "        self.out = nn.Linear(dense, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.PreprocBlock(x)\n",
    "        x = self.LBCChain(x)\n",
    "        x = self.AvgPooling(x)\n",
    "        \n",
    "        x = x.view(-1, self.flatten_size)        \n",
    "        \n",
    "        x = self.dense(self.dropout(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        t = self.out(x)\n",
    "        \n",
    "        return t\n",
    "    \n",
    "    \n",
    "class ResNet_MNIST_Runner():\n",
    "    def __init__(self, dense=False, shared=False, log_interval=200):\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        self.isCuda = torch.cuda.is_available()\n",
    "        self.log_interval = log_interval\n",
    "        self.vis = visdom.Visdom(port=8889)\n",
    "        self.dense = dense\n",
    "        self.shared = shared\n",
    "        \n",
    "        if not self.vis.check_connection():\n",
    "            raise RuntimeError(\"Visdom server not running. Please run python -m visdom.server\")\n",
    "            \n",
    "    \n",
    "    def __load_data(self):\n",
    "        trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=self.transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=8)\n",
    "        \n",
    "        testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=self.transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=8)\n",
    "        \n",
    "    \n",
    "    def compile_model(self, n_channels=16, n_weights=512, lbc_depth=75, n_dense=128, sparsity=0.5):\n",
    "        \n",
    "        self.__load_data()\n",
    "        self.start_epoch = 0\n",
    "        self.arch = [n_channels, n_weights, lbc_depth, n_dense, sparsity]\n",
    "        \n",
    "        if (self.isCuda):\n",
    "            if (self.dense):\n",
    "                self.model = ResNet_MNIST_DENSE(n_channels, n_weights, lbc_depth, n_dense, sparsity).cuda()\n",
    "            else:\n",
    "                self.model = ResNet_MNIST(n_channels, n_weights, lbc_depth, n_dense, sparsity, self.shared).cuda()\n",
    "        else:\n",
    "            if (self.dense):\n",
    "                self.model = ResNet_MNIST_DENSE(n_channels, n_weights, lbc_depth, n_dense, sparsity)\n",
    "            else:\n",
    "                self.model = ResNet_MNIST(n_channels, n_weights, lbc_depth, n_dense, sparsity, self.shared)\n",
    "                \n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()))\n",
    "        \n",
    "        self.trainer = create_supervised_trainer(self.model, self.optimizer, F.cross_entropy, cuda=self.isCuda)\n",
    "        self.evaluator = create_supervised_evaluator(self.model,\n",
    "                                            metrics={'accuracy': CategoricalAccuracy(),\n",
    "                                                     'loss': Loss(F.cross_entropy)},\n",
    "                                            cuda=self.isCuda)\n",
    "    \n",
    "    \n",
    "        self.best_acc = 0.0\n",
    "        self.val_loss = 0.0\n",
    "        self.val_acc = 0.0\n",
    "    \n",
    "            \n",
    "    def __create_plot_window(self, vis, xlabel, ylabel, title):\n",
    "        return vis.line(X=np.array([1]), Y=np.array([np.nan]), opts=dict(xlabel=xlabel, ylabel=ylabel, title=title))\n",
    "    \n",
    "    def __imshow(self, img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "        \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "    \n",
    "    \n",
    "    def __checkpointModel(self, epoch, current_acc):\n",
    "        self.__save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'best_prec1': self.best_acc,\n",
    "            'optimizer' : self.optimizer.state_dict(),\n",
    "            'arch': self.arch\n",
    "        }, current_acc > self.best_acc)\n",
    "    \n",
    "    def __save_checkpoint(self, state, is_best, filename='checkpoints/MNIST/MNIST_checkpoint.pth.tar'):\n",
    "        torch.save(state, filename)\n",
    "        if is_best:\n",
    "            shutil.copyfile(filename, 'checkpoints/MNIST/MNIST_model_best.pth.tar')\n",
    "            \n",
    "            \n",
    "    def resume(self, best = True, create_views = False):\n",
    "        if (best):\n",
    "            path = 'checkpoints/MNIST/MNIST_model_best.pth.tar'\n",
    "        else:\n",
    "            path = 'checkpoints/MNIST/MNIST_checkpoint.pth.tar'\n",
    "            \n",
    "        if os.path.isfile(path):\n",
    "            print(\"=> loading checkpoint '{}'\".format(path))\n",
    "            \n",
    "            checkpoint = torch.load(path)\n",
    "            self.arch = checkpoint['arch']\n",
    "            self.compile_model(*self.arch)\n",
    "            \n",
    "            \n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            \n",
    "                 \n",
    "            self.start_epoch = checkpoint['epoch']\n",
    "            self.best_acc = checkpoint['best_prec1']\n",
    "            \n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(path, checkpoint['epoch']))\n",
    "            \n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(path))\n",
    "    \n",
    "    def train(self, epochs, verbose=True, graph=False):\n",
    "        trainer = self.trainer\n",
    "        self.start_time = 0.0;\n",
    "        \n",
    "        if graph:\n",
    "            self.train_loss_window = self.__create_plot_window(self.vis, '#Iterations', 'Loss', 'Training Loss')\n",
    "            self.val_accuracy_window = self.__create_plot_window(self.vis, '#Epochs', 'Accuracy', 'Validation Accuracy')\n",
    "            self.val_loss_window = self.__create_plot_window(self.vis, '#Epochs', 'Loss', 'Validation Loss')\n",
    "        \n",
    "        \n",
    "        @trainer.on(Events.EPOCH_STARTED)\n",
    "        def resume_from_epoch(engine):\n",
    "            self.start_time = time.time()\n",
    "            if (engine.state.epoch < self.start_epoch):\n",
    "                engine.state.epoch = self.start_epoch\n",
    "        \n",
    "        @trainer.on(Events.ITERATION_COMPLETED)\n",
    "        def log_training_loss(engine):\n",
    "            iter = (engine.state.iteration - 1) % len(self.trainloader) + 1\n",
    "            if iter % self.log_interval == 0:\n",
    "                if verbose:\n",
    "                    print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f} \".format(engine.state.epoch, iter, len(self.trainloader), engine.state.output))\n",
    "                if graph:\n",
    "                    self.vis.line(X=np.array([engine.state.iteration]), Y=np.array([engine.state.output]), update='append', win=self.train_loss_window)    \n",
    "            \n",
    "        \n",
    "        @trainer.on(Events.EPOCH_COMPLETED)\n",
    "        def log_validation_results(engine):\n",
    "            self.evaluator.run(self.testloader)\n",
    "            metrics = self.evaluator.state.metrics\n",
    "            \n",
    "            avg_accuracy = metrics['accuracy']\n",
    "            avg_loss = metrics['loss']\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(engine.state.epoch, avg_accuracy, avg_loss))\n",
    "            \n",
    "            if graph:\n",
    "                self.vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_accuracy]), win=self.val_accuracy_window, update='append')\n",
    "                self.vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_loss]), win=self.val_loss_window, update='append')\n",
    "    \n",
    "            self.__checkpointModel(engine.state.epoch, avg_accuracy)\n",
    "        \n",
    "            if (avg_accuracy > self.best_acc):\n",
    "                self.best_acc = avg_accuracy\n",
    "                \n",
    "            self.val_acc = avg_accuracy\n",
    "            self.val_loss = avg_loss\n",
    "                \n",
    "            if verbose:\n",
    "                print(\"Epoch: %d - Time: %s seconds.\" %(engine.state.epoch,(round(time.time() - self.start_time, 0))))\n",
    "        \n",
    "        trainer.run(self.trainloader, max_epochs=epochs)\n",
    "        \n",
    "        return self.best_acc, self.val_loss\n",
    "    \n",
    "    def sample(self, count):\n",
    "        dataiter = iter(self.testloader)\n",
    "        images, labels = dataiter.next()\n",
    "        \n",
    "        self.__imshow(torchvision.utils.make_grid(images[0:count,:,:,:]))\n",
    "        print('GroundTruth\\t: ', ' '.join('%5s \\t' % MNIST_CLASSES[labels[0:count][j]] for j in range(count)))\n",
    "        \n",
    "        if (self.isCuda):\n",
    "            outputs = self.model(Variable(images[0:count,:,:,:].cuda()))\n",
    "        else:\n",
    "            outputs = self.model(Variable(images[0:count,:,:,:]))\n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "        print('Predicted\\t: ', ' '.join('%5s \\t' % MNIST_CLASSES[predicted[j]] for j in range(count)))\n",
    "        \n",
    "    def accuracy(self):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in self.testloader:\n",
    "            images, labels = data\n",
    "            \n",
    "            if (self.isCuda):\n",
    "                outputs = self.model(Variable(images.cuda()))\n",
    "            else:\n",
    "                outputs = self.model(Variable(images))\n",
    "                                     \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            if (self.isCuda):\n",
    "                correct += (predicted == labels.cuda()).sum()\n",
    "            else:\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet_SVHN(nn.Module):\n",
    "    def __init__(self, in_channels, out_features, depth, dense, sparsity=0.1, shared=False):\n",
    "        super(ResNet_SVHN, self).__init__()\n",
    "        \n",
    "        self.PreprocBlock = nn.Sequential(\n",
    "            nn.Conv2d(3, in_channels, kernel_size=3,padding=2),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        if (shared):\n",
    "            W = getWeightMatrix(in_channels, out_features, 3, sparsity)\n",
    "            self.LBCChain = nn.Sequential(*[LBCBlock(in_channels, out_features, sparsity, W) for layer in range(depth)])\n",
    "        else:\n",
    "            self.LBCChain = nn.Sequential(*[LBCBlock(in_channels, out_features, sparsity) for layer in range(depth)])\n",
    "        \n",
    "        self.AvgPooling = nn.AvgPool2d(5,5)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten_size = in_channels * 6 * 6\n",
    "        self.dense = nn.Linear(self.flatten_size, dense)\n",
    "        self.out = nn.Linear(dense, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.PreprocBlock(x)\n",
    "        x = self.LBCChain(x)\n",
    "        x = self.AvgPooling(x)\n",
    "        \n",
    "        x = x.view(-1, self.flatten_size)        \n",
    "        \n",
    "        x = self.dense(self.dropout(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        t = self.out(x)\n",
    "        \n",
    "        return t\n",
    "    \n",
    "class ResNet_SVHN_DENSE(nn.Module):\n",
    "    def __init__(self, in_channels, out_features, depth, dense, sparsity=0.1):\n",
    "        super(ResNet_SVHN_DENSE, self).__init__()\n",
    "        \n",
    "        self.PreprocBlock = nn.Sequential(\n",
    "            nn.Conv2d(3, in_channels, kernel_size=3,padding=2),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.LBCChain = nn.Sequential(*[LBCBlock_DENSE(in_channels, out_features, sparsity=sparsity) for layer in range(depth)])\n",
    "        self.AvgPooling = nn.AvgPool2d(5,5)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten_size = in_channels * 6 * 6\n",
    "        self.dense = nn.Linear(self.flatten_size, dense)\n",
    "        self.out = nn.Linear(dense, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.PreprocBlock(x)\n",
    "        x = self.LBCChain(x)\n",
    "        x = self.AvgPooling(x)\n",
    "        \n",
    "        x = x.view(-1, self.flatten_size)        \n",
    "        \n",
    "        x = self.dense(self.dropout(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        t = self.out(x)\n",
    "        \n",
    "        return t\n",
    "    \n",
    "class ResNet_SVHN_Runner():\n",
    "    def __init__(self, dense=False, shared=False, log_interval=200):\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        self.isCuda = torch.cuda.is_available()\n",
    "        self.log_interval = log_interval\n",
    "        self.vis = visdom.Visdom(port=8889)\n",
    "        self.dense = dense\n",
    "        self.shared = shared\n",
    "        \n",
    "        if not self.vis.check_connection():\n",
    "            raise RuntimeError(\"Visdom server not running. Please run python -m visdom.server\")\n",
    "            \n",
    "    \n",
    "    def __load_data(self):\n",
    "        trainset = torchvision.datasets.SVHN(root='./data', split='train', download=True, transform=self.transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=8)\n",
    "        \n",
    "        testset = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=self.transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=8)\n",
    "        \n",
    "    \n",
    "    def compile_model(self, n_channels=16, n_weights=512, lbc_depth=40, n_dense=512, sparsity=0.9):\n",
    "        \n",
    "        self.__load_data()\n",
    "        self.start_epoch = 0\n",
    "        self.arch = [n_channels, n_weights, lbc_depth, n_dense, sparsity]\n",
    "        \n",
    "        \n",
    "        if (self.isCuda):\n",
    "            if (self.dense):\n",
    "                self.model = ResNet_SVHN_DENSE(n_channels, n_weights, lbc_depth, n_dense, sparsity).cuda()\n",
    "            else:\n",
    "                self.model = ResNet_SVHN(n_channels, n_weights, lbc_depth, n_dense, sparsity, self.shared).cuda()\n",
    "        else:\n",
    "            if (self.dense):\n",
    "                self.model = ResNet_SVHN_DENSE(n_channels, n_weights, lbc_depth, n_dense, sparsity)\n",
    "            else:\n",
    "                self.model = ResNet_SVHN(n_channels, n_weights, lbc_depth, n_dense, sparsity, self.shared)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()))\n",
    "        \n",
    "        self.trainer = create_supervised_trainer(self.model, self.optimizer, F.cross_entropy, cuda=self.isCuda)\n",
    "        self.evaluator = create_supervised_evaluator(self.model,\n",
    "                                            metrics={'accuracy': CategoricalAccuracy(),\n",
    "                                                     'loss': Loss(F.cross_entropy)},\n",
    "                                            cuda=self.isCuda)\n",
    "    \n",
    "    \n",
    "        self.best_acc = 0.0\n",
    "    \n",
    "            \n",
    "    def __create_plot_window(self, vis, xlabel, ylabel, title):\n",
    "        return vis.line(X=np.array([1]), Y=np.array([np.nan]), opts=dict(xlabel=xlabel, ylabel=ylabel, title=title))\n",
    "    \n",
    "    def __imshow(self, img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "        \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "    \n",
    "    \n",
    "    def __checkpointModel(self, epoch, current_acc):\n",
    "        self.__save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'best_prec1': self.best_acc,\n",
    "            'optimizer' : self.optimizer.state_dict(),\n",
    "            'arch': self.arch\n",
    "        }, current_acc > self.best_acc)\n",
    "    \n",
    "    def __save_checkpoint(self, state, is_best, filename='checkpoints/SVHN/SVHN_checkpoint.pth.tar'):\n",
    "        torch.save(state, filename)\n",
    "        if is_best:\n",
    "            shutil.copyfile(filename, 'checkpoints/SVHN/SVHN_model_best.pth.tar')\n",
    "            \n",
    "            \n",
    "    def resume(self, best = True):\n",
    "        if (best):\n",
    "            path = 'checkpoints/SVHN/SVHN_model_best.pth.tar'\n",
    "        else:\n",
    "            path = 'checkpoints/SVHN/SVHN_checkpoint.pth.tar'\n",
    "            \n",
    "        if os.path.isfile(path):\n",
    "            print(\"=> loading checkpoint '{}'\".format(path))\n",
    "            \n",
    "            checkpoint = torch.load(path)\n",
    "            self.arch = checkpoint['arch']\n",
    "            self.compile_model(*self.arch)\n",
    "            \n",
    "            \n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            \n",
    "                 \n",
    "            self.start_epoch = checkpoint['epoch']\n",
    "            self.best_acc = checkpoint['best_prec1']\n",
    "            \n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(path, checkpoint['epoch']))\n",
    "            \n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(path))\n",
    "    \n",
    "    def train(self, epochs, verbose=True, graph=False):\n",
    "        trainer = self.trainer\n",
    "        self.start_time = 0.0;\n",
    "        \n",
    "        \n",
    "        if graph:\n",
    "            self.train_loss_window = self.__create_plot_window(self.vis, '#Iterations', 'Loss', 'Training Loss')\n",
    "            self.val_accuracy_window = self.__create_plot_window(self.vis, '#Epochs', 'Accuracy', 'Validation Accuracy')\n",
    "            self.val_loss_window = self.__create_plot_window(self.vis, '#Epochs', 'Loss', 'Validation Loss')\n",
    "        \n",
    "        \n",
    "        @trainer.on(Events.EPOCH_STARTED)\n",
    "        def resume_from_epoch(engine):\n",
    "            self.start_time = time.time()\n",
    "            if (engine.state.epoch < self.start_epoch):\n",
    "                engine.state.epoch = self.start_epoch\n",
    "        \n",
    "        @trainer.on(Events.ITERATION_COMPLETED)\n",
    "        def log_training_loss(engine):\n",
    "            iter = (engine.state.iteration - 1) % len(self.trainloader) + 1\n",
    "            if iter % self.log_interval == 0:\n",
    "                if (verbose):\n",
    "                    print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f} \".format(engine.state.epoch, iter, len(self.trainloader), engine.state.output))\n",
    "                if graph:\n",
    "                    self.vis.line(X=np.array([engine.state.iteration]), Y=np.array([engine.state.output]), update='append', win=self.train_loss_window)    \n",
    "            \n",
    "        \n",
    "        @trainer.on(Events.EPOCH_COMPLETED)\n",
    "        def log_validation_results(engine):\n",
    "            self.evaluator.run(self.testloader)\n",
    "            metrics = self.evaluator.state.metrics\n",
    "            \n",
    "            avg_accuracy = metrics['accuracy']\n",
    "            avg_loss = metrics['loss']\n",
    "            if (verbose):\n",
    "                print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(engine.state.epoch, avg_accuracy, avg_loss))\n",
    "            \n",
    "            if graph:\n",
    "                self.vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_accuracy]), win=self.val_accuracy_window, update='append')\n",
    "                self.vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_loss]), win=self.val_loss_window, update='append')\n",
    "    \n",
    "            self.__checkpointModel(engine.state.epoch, avg_accuracy)\n",
    "        \n",
    "            if (avg_accuracy > self.best_acc):\n",
    "                self.best_acc = avg_accuracy\n",
    "            \n",
    "            if (verbose):\n",
    "                print(\"Epoch: %d - Time: %s seconds.\" %(engine.state.epoch,(round(time.time() - self.start_time, 0))))\n",
    "        \n",
    "        trainer.run(self.trainloader, max_epochs=epochs)\n",
    "    \n",
    "    def sample(self, count):\n",
    "        dataiter = iter(self.testloader)\n",
    "        images, labels = dataiter.next()\n",
    "        \n",
    "        self.__imshow(torchvision.utils.make_grid(images[0:count,:,:,:]))\n",
    "        print('GroundTruth\\t: ', ' '.join('%5s \\t' % MNIST_CLASSES[labels[0:count][j]] for j in range(count)))\n",
    "        \n",
    "        if (self.isCuda):\n",
    "            outputs = self.model(Variable(images[0:count,:,:,:].cuda()))\n",
    "        else:\n",
    "            outputs = self.model(Variable(images[0:count,:,:,:]))\n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "        print('Predicted\\t: ', ' '.join('%5s \\t' % MNIST_CLASSES[predicted[j]] for j in range(count)))\n",
    "              \n",
    "                \n",
    "        \n",
    "    def accuracy(self):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in self.testloader:\n",
    "            images, labels = data\n",
    "            \n",
    "            if (self.isCuda):\n",
    "                outputs = self.model(Variable(images.cuda()))\n",
    "            else:\n",
    "                outputs = self.model(Variable(images))\n",
    "                                     \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            if (self.isCuda):\n",
    "                correct += (predicted == labels.cuda()).sum()\n",
    "            else:\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %.2f %%' % (100 * correct / total))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a MNIST runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_runner = ResNet_MNIST_Runner(dense=False,shared=False,log_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model with default architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_runner.compile_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile model with custom architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_runner.compile_model(16,32,5,64, 0.5) ## simple lbcnn (shallow) 0.9866 on MNIST after 30 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model for 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[100/469] Loss: 0.90 \n",
      "Epoch[1] Iteration[200/469] Loss: 0.49 \n",
      "Epoch[1] Iteration[300/469] Loss: 0.48 \n",
      "Epoch[1] Iteration[400/469] Loss: 0.44 \n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.93 Avg loss: 0.25\n",
      "Epoch: 1 - Time: 6.0 seconds.\n",
      "Epoch[2] Iteration[100/469] Loss: 0.43 \n",
      "Epoch[2] Iteration[200/469] Loss: 0.35 \n",
      "Epoch[2] Iteration[300/469] Loss: 0.31 \n",
      "Epoch[2] Iteration[400/469] Loss: 0.41 \n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.95 Avg loss: 0.17\n",
      "Epoch: 2 - Time: 6.0 seconds.\n",
      "Epoch[3] Iteration[100/469] Loss: 0.21 \n",
      "Epoch[3] Iteration[200/469] Loss: 0.24 \n",
      "Epoch[3] Iteration[300/469] Loss: 0.45 \n",
      "Epoch[3] Iteration[400/469] Loss: 0.30 \n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.96 Avg loss: 0.14\n",
      "Epoch: 3 - Time: 6.0 seconds.\n",
      "Epoch[4] Iteration[100/469] Loss: 0.42 \n",
      "Epoch[4] Iteration[200/469] Loss: 0.27 \n",
      "Epoch[4] Iteration[300/469] Loss: 0.24 \n",
      "Epoch[4] Iteration[400/469] Loss: 0.20 \n",
      "Validation Results - Epoch: 4  Avg accuracy: 0.97 Avg loss: 0.12\n",
      "Epoch: 4 - Time: 6.0 seconds.\n",
      "Epoch[5] Iteration[100/469] Loss: 0.38 \n",
      "Epoch[5] Iteration[200/469] Loss: 0.34 \n",
      "Epoch[5] Iteration[300/469] Loss: 0.19 \n",
      "Epoch[5] Iteration[400/469] Loss: 0.15 \n",
      "Validation Results - Epoch: 5  Avg accuracy: 0.97 Avg loss: 0.10\n",
      "Epoch: 5 - Time: 6.0 seconds.\n",
      "Epoch[6] Iteration[100/469] Loss: 0.23 \n",
      "Epoch[6] Iteration[200/469] Loss: 0.29 \n",
      "Epoch[6] Iteration[300/469] Loss: 0.25 \n",
      "Epoch[6] Iteration[400/469] Loss: 0.16 \n",
      "Validation Results - Epoch: 6  Avg accuracy: 0.97 Avg loss: 0.10\n",
      "Epoch: 6 - Time: 6.0 seconds.\n",
      "Epoch[7] Iteration[100/469] Loss: 0.22 \n",
      "Epoch[7] Iteration[200/469] Loss: 0.18 \n",
      "Epoch[7] Iteration[300/469] Loss: 0.22 \n",
      "Epoch[7] Iteration[400/469] Loss: 0.21 \n",
      "Validation Results - Epoch: 7  Avg accuracy: 0.97 Avg loss: 0.09\n",
      "Epoch: 7 - Time: 6.0 seconds.\n",
      "Epoch[8] Iteration[100/469] Loss: 0.12 \n",
      "Epoch[8] Iteration[200/469] Loss: 0.23 \n",
      "Epoch[8] Iteration[300/469] Loss: 0.16 \n",
      "Epoch[8] Iteration[400/469] Loss: 0.24 \n",
      "Validation Results - Epoch: 8  Avg accuracy: 0.97 Avg loss: 0.08\n",
      "Epoch: 8 - Time: 6.0 seconds.\n",
      "Epoch[9] Iteration[100/469] Loss: 0.20 \n",
      "Epoch[9] Iteration[200/469] Loss: 0.17 \n",
      "Epoch[9] Iteration[300/469] Loss: 0.09 \n",
      "Epoch[9] Iteration[400/469] Loss: 0.21 \n",
      "Validation Results - Epoch: 9  Avg accuracy: 0.98 Avg loss: 0.08\n",
      "Epoch: 9 - Time: 6.0 seconds.\n",
      "Epoch[10] Iteration[100/469] Loss: 0.19 \n",
      "Epoch[10] Iteration[200/469] Loss: 0.15 \n",
      "Epoch[10] Iteration[300/469] Loss: 0.27 \n",
      "Epoch[10] Iteration[400/469] Loss: 0.23 \n",
      "Validation Results - Epoch: 10  Avg accuracy: 0.98 Avg loss: 0.07\n",
      "Epoch: 10 - Time: 6.0 seconds.\n",
      "Epoch[11] Iteration[100/469] Loss: 0.12 \n",
      "Epoch[11] Iteration[200/469] Loss: 0.16 \n",
      "Epoch[11] Iteration[300/469] Loss: 0.16 \n",
      "Epoch[11] Iteration[400/469] Loss: 0.21 \n",
      "Validation Results - Epoch: 11  Avg accuracy: 0.98 Avg loss: 0.07\n",
      "Epoch: 11 - Time: 6.0 seconds.\n",
      "Epoch[12] Iteration[100/469] Loss: 0.19 \n",
      "Epoch[12] Iteration[200/469] Loss: 0.29 \n",
      "Epoch[12] Iteration[300/469] Loss: 0.18 \n",
      "Epoch[12] Iteration[400/469] Loss: 0.18 \n",
      "Validation Results - Epoch: 12  Avg accuracy: 0.98 Avg loss: 0.07\n",
      "Epoch: 12 - Time: 6.0 seconds.\n",
      "Epoch[13] Iteration[100/469] Loss: 0.16 \n",
      "Epoch[13] Iteration[200/469] Loss: 0.20 \n",
      "Epoch[13] Iteration[300/469] Loss: 0.10 \n",
      "Epoch[13] Iteration[400/469] Loss: 0.21 \n",
      "Validation Results - Epoch: 13  Avg accuracy: 0.98 Avg loss: 0.06\n",
      "Epoch: 13 - Time: 6.0 seconds.\n",
      "Epoch[14] Iteration[100/469] Loss: 0.25 \n",
      "Epoch[14] Iteration[200/469] Loss: 0.13 \n",
      "Epoch[14] Iteration[300/469] Loss: 0.16 \n",
      "Epoch[14] Iteration[400/469] Loss: 0.07 \n",
      "Validation Results - Epoch: 14  Avg accuracy: 0.98 Avg loss: 0.06\n",
      "Epoch: 14 - Time: 6.0 seconds.\n",
      "Epoch[15] Iteration[100/469] Loss: 0.17 \n",
      "Epoch[15] Iteration[200/469] Loss: 0.11 \n",
      "Epoch[15] Iteration[300/469] Loss: 0.13 \n",
      "Epoch[15] Iteration[400/469] Loss: 0.20 \n",
      "Validation Results - Epoch: 15  Avg accuracy: 0.98 Avg loss: 0.06\n",
      "Epoch: 15 - Time: 6.0 seconds.\n",
      "Epoch[16] Iteration[100/469] Loss: 0.21 \n",
      "Epoch[16] Iteration[200/469] Loss: 0.19 \n",
      "Epoch[16] Iteration[300/469] Loss: 0.29 \n",
      "Epoch[16] Iteration[400/469] Loss: 0.14 \n",
      "Validation Results - Epoch: 16  Avg accuracy: 0.98 Avg loss: 0.06\n",
      "Epoch: 16 - Time: 6.0 seconds.\n",
      "Epoch[17] Iteration[100/469] Loss: 0.15 \n",
      "Epoch[17] Iteration[200/469] Loss: 0.12 \n",
      "Epoch[17] Iteration[300/469] Loss: 0.09 \n",
      "Epoch[17] Iteration[400/469] Loss: 0.10 \n",
      "Validation Results - Epoch: 17  Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Epoch: 17 - Time: 6.0 seconds.\n",
      "Epoch[18] Iteration[100/469] Loss: 0.04 \n",
      "Epoch[18] Iteration[200/469] Loss: 0.18 \n",
      "Epoch[18] Iteration[300/469] Loss: 0.14 \n",
      "Epoch[18] Iteration[400/469] Loss: 0.16 \n",
      "Validation Results - Epoch: 18  Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Epoch: 18 - Time: 6.0 seconds.\n",
      "Epoch[19] Iteration[100/469] Loss: 0.09 \n",
      "Epoch[19] Iteration[200/469] Loss: 0.19 \n",
      "Epoch[19] Iteration[300/469] Loss: 0.30 \n",
      "Epoch[19] Iteration[400/469] Loss: 0.13 \n",
      "Validation Results - Epoch: 19  Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Epoch: 19 - Time: 6.0 seconds.\n",
      "Epoch[20] Iteration[100/469] Loss: 0.10 \n",
      "Epoch[20] Iteration[200/469] Loss: 0.11 \n",
      "Epoch[20] Iteration[300/469] Loss: 0.10 \n",
      "Epoch[20] Iteration[400/469] Loss: 0.05 \n",
      "Validation Results - Epoch: 20  Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Epoch: 20 - Time: 6.0 seconds.\n",
      "Epoch[21] Iteration[100/469] Loss: 0.27 \n",
      "Epoch[21] Iteration[200/469] Loss: 0.08 \n",
      "Epoch[21] Iteration[300/469] Loss: 0.26 \n",
      "Epoch[21] Iteration[400/469] Loss: 0.15 \n",
      "Validation Results - Epoch: 21  Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Epoch: 21 - Time: 6.0 seconds.\n",
      "Epoch[22] Iteration[100/469] Loss: 0.14 \n",
      "Epoch[22] Iteration[200/469] Loss: 0.09 \n",
      "Epoch[22] Iteration[300/469] Loss: 0.10 \n",
      "Epoch[22] Iteration[400/469] Loss: 0.18 \n",
      "Validation Results - Epoch: 22  Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Epoch: 22 - Time: 6.0 seconds.\n",
      "Epoch[23] Iteration[100/469] Loss: 0.29 \n",
      "Epoch[23] Iteration[200/469] Loss: 0.09 \n",
      "Epoch[23] Iteration[300/469] Loss: 0.09 \n",
      "Epoch[23] Iteration[400/469] Loss: 0.13 \n",
      "Validation Results - Epoch: 23  Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Epoch: 23 - Time: 6.0 seconds.\n",
      "Epoch[24] Iteration[100/469] Loss: 0.17 \n",
      "Epoch[24] Iteration[200/469] Loss: 0.07 \n",
      "Epoch[24] Iteration[300/469] Loss: 0.20 \n",
      "Epoch[24] Iteration[400/469] Loss: 0.24 \n",
      "Validation Results - Epoch: 24  Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Epoch: 24 - Time: 6.0 seconds.\n",
      "Epoch[25] Iteration[100/469] Loss: 0.09 \n",
      "Epoch[25] Iteration[200/469] Loss: 0.09 \n",
      "Epoch[25] Iteration[300/469] Loss: 0.14 \n",
      "Epoch[25] Iteration[400/469] Loss: 0.05 \n",
      "Validation Results - Epoch: 25  Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Epoch: 25 - Time: 6.0 seconds.\n",
      "Epoch[26] Iteration[100/469] Loss: 0.17 \n",
      "Epoch[26] Iteration[200/469] Loss: 0.08 \n",
      "Epoch[26] Iteration[300/469] Loss: 0.06 \n",
      "Epoch[26] Iteration[400/469] Loss: 0.07 \n",
      "Validation Results - Epoch: 26  Avg accuracy: 0.99 Avg loss: 0.05\n",
      "Epoch: 26 - Time: 6.0 seconds.\n",
      "Epoch[27] Iteration[100/469] Loss: 0.11 \n",
      "Epoch[27] Iteration[200/469] Loss: 0.15 \n",
      "Epoch[27] Iteration[300/469] Loss: 0.06 \n",
      "Epoch[27] Iteration[400/469] Loss: 0.05 \n",
      "Validation Results - Epoch: 27  Avg accuracy: 0.99 Avg loss: 0.05\n",
      "Epoch: 27 - Time: 6.0 seconds.\n",
      "Epoch[28] Iteration[100/469] Loss: 0.07 \n",
      "Epoch[28] Iteration[200/469] Loss: 0.08 \n",
      "Epoch[28] Iteration[300/469] Loss: 0.13 \n",
      "Epoch[28] Iteration[400/469] Loss: 0.14 \n",
      "Validation Results - Epoch: 28  Avg accuracy: 0.99 Avg loss: 0.04\n",
      "Epoch: 28 - Time: 6.0 seconds.\n",
      "Epoch[29] Iteration[100/469] Loss: 0.04 \n",
      "Epoch[29] Iteration[200/469] Loss: 0.04 \n",
      "Epoch[29] Iteration[300/469] Loss: 0.10 \n",
      "Epoch[29] Iteration[400/469] Loss: 0.09 \n",
      "Validation Results - Epoch: 29  Avg accuracy: 0.99 Avg loss: 0.04\n",
      "Epoch: 29 - Time: 6.0 seconds.\n",
      "Epoch[30] Iteration[100/469] Loss: 0.08 \n",
      "Epoch[30] Iteration[200/469] Loss: 0.04 \n",
      "Epoch[30] Iteration[300/469] Loss: 0.05 \n",
      "Epoch[30] Iteration[400/469] Loss: 0.15 \n",
      "Validation Results - Epoch: 30  Avg accuracy: 0.99 Avg loss: 0.04\n",
      "Epoch: 30 - Time: 6.0 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9866, 0.04222807469367981)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_runner.train(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some sample results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth\t:      7 \t     2 \t     1 \t     0 \t\n",
      "Predicted\t:      7 \t     2 \t     1 \t     0 \t\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE7U+9fYMxlsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_runner.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 98.66 %\n"
     ]
    }
   ],
   "source": [
    "mnist_runner.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can also create an equivalent dense MNIST runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_runner = ResNet_MNIST_Runner(dense=True,shared=False,log_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LBCNN using weight sharing (as defined in paper)\n",
    "Note: We didn't focus on computational performance optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_runner = ResNet_MNIST_Runner(dense=False,shared=True,log_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same idea for SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "svhn_runner = ResNet_SVHN_Runner(dense=False,shared=False, log_interval=100)\n",
    "svhn_runner.compile_model(4,16,4,32) ## custom shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[100/573] Loss: 2.25 \n",
      "Epoch[1] Iteration[200/573] Loss: 2.18 \n",
      "Epoch[1] Iteration[300/573] Loss: 2.16 \n",
      "Epoch[1] Iteration[400/573] Loss: 2.16 \n",
      "Epoch[1] Iteration[500/573] Loss: 2.19 \n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.32 Avg loss: 2.04\n",
      "Epoch: 1 - Time: 6.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "svhn_runner.train(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resuming a model from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'checkpoints/SVHN/SVHN_model_best.pth.tar'\n",
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "=> loaded checkpoint 'checkpoints/SVHN/SVHN_model_best.pth.tar' (epoch 2)\n"
     ]
    }
   ],
   "source": [
    "svhn_runner = ResNet_SVHN_Runner(log_interval=100)\n",
    "svhn_runner.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2] Iteration[100/573] Loss: 1.63 \n",
      "Epoch[2] Iteration[100/573] Loss: 1.63 \n",
      "Epoch[2] Iteration[200/573] Loss: 1.57 \n",
      "Epoch[2] Iteration[200/573] Loss: 1.57 \n",
      "Epoch[2] Iteration[300/573] Loss: 1.56 \n",
      "Epoch[2] Iteration[300/573] Loss: 1.56 \n",
      "Epoch[2] Iteration[400/573] Loss: 1.51 \n",
      "Epoch[2] Iteration[400/573] Loss: 1.51 \n",
      "Epoch[2] Iteration[500/573] Loss: 1.42 \n",
      "Epoch[2] Iteration[500/573] Loss: 1.42 \n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.69 Avg loss: 1.13\n",
      "Epoch: 2 - Time: 6.0 seconds.\n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.69 Avg loss: 1.13\n",
      "Epoch: 2 - Time: 9.0 seconds.\n",
      "Epoch[3] Iteration[100/573] Loss: 1.44 \n",
      "Epoch[3] Iteration[100/573] Loss: 1.44 \n",
      "Epoch[3] Iteration[200/573] Loss: 1.37 \n",
      "Epoch[3] Iteration[200/573] Loss: 1.37 \n",
      "Epoch[3] Iteration[300/573] Loss: 1.50 \n",
      "Epoch[3] Iteration[300/573] Loss: 1.50 \n",
      "Epoch[3] Iteration[400/573] Loss: 1.39 \n",
      "Epoch[3] Iteration[400/573] Loss: 1.39 \n",
      "Epoch[3] Iteration[500/573] Loss: 1.50 \n",
      "Epoch[3] Iteration[500/573] Loss: 1.50 \n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.70 Avg loss: 1.11\n",
      "Epoch: 3 - Time: 7.0 seconds.\n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.70 Avg loss: 1.11\n",
      "Epoch: 3 - Time: 9.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "svhn_runner.train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth\t:      5 \t     2 \t     1 \t     0 \t\n",
      "Predicted\t:      8 \t     2 \t     2 \t     2 \t\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3EkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svhn_runner.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
