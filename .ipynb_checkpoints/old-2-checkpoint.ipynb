{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.magic import register_line_magic\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from ignite.engines import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import CategoricalAccuracy, Loss\n",
    "\n",
    "try:\n",
    "    import visdom\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"No visdom package is found. Please install it with command: \\n pip install visdom\")\n",
    "\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import gc\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torchnet as tnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_CLASSES = ('0', '1', '2', '3', '4', '5', '6' ,'7', '8', '9')\n",
    "\n",
    "BATCH_SIZE_TRAIN = 512\n",
    "BATCH_SIZE_TEST = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@register_line_magic\n",
    "def pip(args):\n",
    "    \"\"\"Use pip from the current kernel\"\"\"\n",
    "    from pip import main\n",
    "    main(args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def getWeights(in_channels, out_channels, kernel_size, sparsity):\n",
    "    W_size = torch.Size([out_channels,in_channels,kernel_size,kernel_size]) \n",
    "    W = torch.sparse.FloatTensor(W_size)\n",
    "    uniform = torch.FloatTensor(W_size).fill_(0.5)\n",
    "    W = torch.bernoulli(uniform) * 2 - 1\n",
    "    rand = torch.rand(W_size)\n",
    "    mask = rand > sparsity\n",
    "\n",
    "    W.masked_fill_(mask, 0)\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "class LBCFilter(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, sparsity, W = None):\n",
    "        super(LBCFilter, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.ConvModule = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1, bias=False)\n",
    "        if (W is None):\n",
    "            W = getWeights(in_channels, out_channels, kernel_size, sparsity)\n",
    "        \n",
    "        self.ConvModule.weight = nn.Parameter(W, requires_grad=False)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.ConvModule.forward(x)\n",
    "        \n",
    "\n",
    "\n",
    "class LBCBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_size=3, sparsity=0.9, W = None):\n",
    "        super(LBCBlock, self).__init__()\n",
    "        self.Batch_Norm = nn.BatchNorm2d(in_channels)\n",
    "        self.LBCModule = LBCFilter(in_channels, out_channels, 3, sparsity, W)\n",
    "        self.Conv2d = nn.Conv2d(out_channels, in_channels, kernel_size=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        residual = x\n",
    "        \n",
    "        out = self.Batch_Norm(x)\n",
    "        out = F.relu(self.LBCModule(out))\n",
    "        out = self.Conv2d(out)\n",
    "        \n",
    "        out += residual\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class LBCBlock_DENSE(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_size=3, sparsity=0.9):\n",
    "        super(LBCBlock_DENSE, self).__init__()\n",
    "        \n",
    "        self.Batch_Norm = nn.BatchNorm2d(in_channels)\n",
    "        self.LBCModule = nn.Conv2d(in_channels, out_channels,kernel_size=(3,3),padding=1, bias=False)\n",
    "        self.Conv2d = nn.Conv2d(out_channels, in_channels, kernel_size=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        residual = x\n",
    "        \n",
    "        out = self.Batch_Norm(x)\n",
    "        out = F.relu(self.LBCModule(out))\n",
    "        out = self.Conv2d(out)\n",
    "        \n",
    "        out += residual\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet_MNIST(nn.Module):\n",
    "    def __init__(self, in_channels, out_features, depth, dense, sparsity=0.1, shared = False):\n",
    "        super(ResNet_MNIST, self).__init__()\n",
    "        self.PreprocBlock = nn.Sequential(\n",
    "            nn.Conv2d(1, in_channels, kernel_size=3,padding=2),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        if (shared):\n",
    "            W = getWeightMatrix(in_channels, out_features, 3, sparsity)\n",
    "            self.LBCChain = nn.Sequential(*[LBCBlock(in_channels, out_features, 3, sparsity, W) for layer in range(depth)])\n",
    "            \n",
    "        else:\n",
    "            self.LBCChain = nn.Sequential(*[LBCBlock(in_channels, out_features, 3, sparsity) for layer in range(depth)])\n",
    "        \n",
    "        self.AvgPooling = nn.AvgPool2d(5,5)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten_size = in_channels * 6 * 6\n",
    "        self.dense = nn.Linear(self.flatten_size, dense)\n",
    "        self.out = nn.Linear(dense, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.PreprocBlock(x)\n",
    "        x = self.LBCChain(x)\n",
    "        x = self.AvgPooling(x)\n",
    "        \n",
    "        x = x.view(-1, self.flatten_size)        \n",
    "        \n",
    "        x = self.dense(self.dropout(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        t = self.out(x)\n",
    "        \n",
    "        return t\n",
    "    \n",
    "    \n",
    "class ResNet_MNIST_DENSE(nn.Module):\n",
    "    def __init__(self, in_channels, out_features, depth, dense, sparsity=0.1):\n",
    "        super(ResNet_MNIST_DENSE, self).__init__()\n",
    "        \n",
    "        self.PreprocBlock = nn.Sequential(\n",
    "            nn.Conv2d(1, in_channels, kernel_size=3,padding=2),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.LBCChain = nn.Sequential(*[LBCBlock_DENSE(in_channels, out_features, sparsity) for layer in range(depth)])\n",
    "        self.AvgPooling = nn.AvgPool2d(5,5)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten_size = in_channels * 6 * 6\n",
    "        self.dense = nn.Linear(self.flatten_size, dense)\n",
    "        self.out = nn.Linear(dense, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.PreprocBlock(x)\n",
    "        x = self.LBCChain(x)\n",
    "        x = self.AvgPooling(x)\n",
    "        \n",
    "        x = x.view(-1, self.flatten_size)        \n",
    "        \n",
    "        x = self.dense(self.dropout(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        t = self.out(x)\n",
    "        \n",
    "        return t\n",
    "    \n",
    "    \n",
    "class ResNet_MNIST_Runner():\n",
    "    def __init__(self, dense=False, shared=False, log_interval=200):\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        self.isCuda = torch.cuda.is_available()\n",
    "        self.log_interval = log_interval\n",
    "        self.vis = visdom.Visdom(port=8889)\n",
    "        self.dense = dense\n",
    "        self.shared = shared\n",
    "        \n",
    "        if not self.vis.check_connection():\n",
    "            raise RuntimeError(\"Visdom server not running. Please run python -m visdom.server\")\n",
    "            \n",
    "    \n",
    "    def __load_data(self):\n",
    "        trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=self.transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=8)\n",
    "        \n",
    "        testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=self.transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=8)\n",
    "        \n",
    "    \n",
    "    def compile_model(self, n_channels=16, n_weights=512, lbc_depth=75, n_dense=128, sparsity=0.5):\n",
    "        \n",
    "        self.__load_data()\n",
    "        self.start_epoch = 0\n",
    "        self.arch = [n_channels, n_weights, lbc_depth, n_dense, sparsity]\n",
    "        \n",
    "        if (self.isCuda):\n",
    "            if (self.dense):\n",
    "                self.model = ResNet_MNIST_DENSE(n_channels, n_weights, lbc_depth, n_dense, sparsity).cuda()\n",
    "            else:\n",
    "                self.model = ResNet_MNIST(n_channels, n_weights, lbc_depth, n_dense, sparsity, self.shared).cuda()\n",
    "        else:\n",
    "            if (self.dense):\n",
    "                self.model = ResNet_MNIST_DENSE(n_channels, n_weights, lbc_depth, n_dense, sparsity)\n",
    "            else:\n",
    "                self.model = ResNet_MNIST(n_channels, n_weights, lbc_depth, n_dense, sparsity, self.shared)\n",
    "                \n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()))\n",
    "        \n",
    "        self.trainer = create_supervised_trainer(self.model, self.optimizer, F.cross_entropy, cuda=self.isCuda)\n",
    "        self.evaluator = create_supervised_evaluator(self.model,\n",
    "                                            metrics={'accuracy': CategoricalAccuracy(),\n",
    "                                                     'loss': Loss(F.cross_entropy)},\n",
    "                                            cuda=self.isCuda)\n",
    "    \n",
    "    \n",
    "        self.best_acc = 0.0\n",
    "        self.val_loss = 0.0\n",
    "        self.val_acc = 0.0\n",
    "    \n",
    "            \n",
    "    def __create_plot_window(self, vis, xlabel, ylabel, title):\n",
    "        return vis.line(X=np.array([1]), Y=np.array([np.nan]), opts=dict(xlabel=xlabel, ylabel=ylabel, title=title))\n",
    "    \n",
    "    def __imshow(self, img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "        \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "    \n",
    "    \n",
    "    def __checkpointModel(self, epoch, current_acc):\n",
    "        self.__save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'best_prec1': self.best_acc,\n",
    "            'optimizer' : self.optimizer.state_dict(),\n",
    "            'arch': self.arch\n",
    "        }, current_acc > self.best_acc)\n",
    "    \n",
    "    def __save_checkpoint(self, state, is_best, filename='checkpoints/MNIST/MNIST_checkpoint.pth.tar'):\n",
    "        torch.save(state, filename)\n",
    "        if is_best:\n",
    "            shutil.copyfile(filename, 'checkpoints/MNIST/MNIST_model_best.pth.tar')\n",
    "            \n",
    "            \n",
    "    def resume(self, best = True, create_views = False):\n",
    "        if (best):\n",
    "            path = 'checkpoints/MNIST/MNIST_model_best.pth.tar'\n",
    "        else:\n",
    "            path = 'checkpoints/MNIST/MNIST_checkpoint.pth.tar'\n",
    "            \n",
    "        if os.path.isfile(path):\n",
    "            print(\"=> loading checkpoint '{}'\".format(path))\n",
    "            \n",
    "            checkpoint = torch.load(path)\n",
    "            self.arch = checkpoint['arch']\n",
    "            self.compile_model(*self.arch)\n",
    "            \n",
    "            \n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            \n",
    "                 \n",
    "            self.start_epoch = checkpoint['epoch']\n",
    "            self.best_acc = checkpoint['best_prec1']\n",
    "            \n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(path, checkpoint['epoch']))\n",
    "            \n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(path))\n",
    "    \n",
    "    def train(self, epochs, verbose=True, graph=False):\n",
    "        trainer = self.trainer\n",
    "        self.start_time = 0.0;\n",
    "        \n",
    "        if graph:\n",
    "            self.train_loss_window = self.__create_plot_window(self.vis, '#Iterations', 'Loss', 'Training Loss')\n",
    "            self.val_accuracy_window = self.__create_plot_window(self.vis, '#Epochs', 'Accuracy', 'Validation Accuracy')\n",
    "            self.val_loss_window = self.__create_plot_window(self.vis, '#Epochs', 'Loss', 'Validation Loss')\n",
    "        \n",
    "        \n",
    "        @trainer.on(Events.EPOCH_STARTED)\n",
    "        def resume_from_epoch(engine):\n",
    "            self.start_time = time.time()\n",
    "            if (engine.state.epoch < self.start_epoch):\n",
    "                engine.state.epoch = self.start_epoch\n",
    "        \n",
    "        @trainer.on(Events.ITERATION_COMPLETED)\n",
    "        def log_training_loss(engine):\n",
    "            iter = (engine.state.iteration - 1) % len(self.trainloader) + 1\n",
    "            if iter % self.log_interval == 0:\n",
    "                if verbose:\n",
    "                    print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f} \".format(engine.state.epoch, iter, len(self.trainloader), engine.state.output))\n",
    "                if graph:\n",
    "                    self.vis.line(X=np.array([engine.state.iteration]), Y=np.array([engine.state.output]), update='append', win=self.train_loss_window)    \n",
    "            \n",
    "        \n",
    "        @trainer.on(Events.EPOCH_COMPLETED)\n",
    "        def log_validation_results(engine):\n",
    "            self.evaluator.run(self.testloader)\n",
    "            metrics = self.evaluator.state.metrics\n",
    "            \n",
    "            avg_accuracy = metrics['accuracy']\n",
    "            avg_loss = metrics['loss']\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(engine.state.epoch, avg_accuracy, avg_loss))\n",
    "            \n",
    "            if graph:\n",
    "                self.vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_accuracy]), win=self.val_accuracy_window, update='append')\n",
    "                self.vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_loss]), win=self.val_loss_window, update='append')\n",
    "    \n",
    "            self.__checkpointModel(engine.state.epoch, avg_accuracy)\n",
    "        \n",
    "            if (avg_accuracy > self.best_acc):\n",
    "                self.best_acc = avg_accuracy\n",
    "                \n",
    "            self.val_acc = avg_accuracy\n",
    "            self.val_loss = avg_loss\n",
    "                \n",
    "            if verbose:\n",
    "                print(\"Epoch: %d - Time: %s seconds.\" %(engine.state.epoch,(round(time.time() - self.start_time, 0))))\n",
    "        \n",
    "        trainer.run(self.trainloader, max_epochs=epochs)\n",
    "        \n",
    "        return self.best_acc, self.val_loss\n",
    "    \n",
    "    def sample(self, count):\n",
    "        dataiter = iter(self.testloader)\n",
    "        images, labels = dataiter.next()\n",
    "        \n",
    "        self.__imshow(torchvision.utils.make_grid(images[0:count,:,:,:]))\n",
    "        print('GroundTruth\\t: ', ' '.join('%5s \\t' % MNIST_CLASSES[labels[0:count][j]] for j in range(count)))\n",
    "        \n",
    "        if (self.isCuda):\n",
    "            outputs = self.model(Variable(images[0:count,:,:,:].cuda()))\n",
    "        else:\n",
    "            outputs = self.model(Variable(images[0:count,:,:,:]))\n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "        print('Predicted\\t: ', ' '.join('%5s \\t' % MNIST_CLASSES[predicted[j]] for j in range(count)))\n",
    "        \n",
    "    def accuracy(self):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in self.testloader:\n",
    "            images, labels = data\n",
    "            \n",
    "            if (self.isCuda):\n",
    "                outputs = self.model(Variable(images.cuda()))\n",
    "            else:\n",
    "                outputs = self.model(Variable(images))\n",
    "                                     \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            if (self.isCuda):\n",
    "                correct += (predicted == labels.cuda()).sum()\n",
    "            else:\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet_SVHN(nn.Module):\n",
    "    def __init__(self, in_channels, out_features, depth, dense, sparsity=0.1, shared=False):\n",
    "        super(ResNet_SVHN, self).__init__()\n",
    "        \n",
    "        self.PreprocBlock = nn.Sequential(\n",
    "            nn.Conv2d(3, in_channels, kernel_size=3,padding=2),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        if (shared):\n",
    "            W = getWeightMatrix(in_channels, out_features, 3, sparsity)\n",
    "            self.LBCChain = nn.Sequential(*[LBCBlock(in_channels, out_features, sparsity, W) for layer in range(depth)])\n",
    "        else:\n",
    "            self.LBCChain = nn.Sequential(*[LBCBlock(in_channels, out_features, sparsity) for layer in range(depth)])\n",
    "        \n",
    "        self.AvgPooling = nn.AvgPool2d(5,5)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten_size = in_channels * 6 * 6\n",
    "        self.dense = nn.Linear(self.flatten_size, dense)\n",
    "        self.out = nn.Linear(dense, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.PreprocBlock(x)\n",
    "        x = self.LBCChain(x)\n",
    "        x = self.AvgPooling(x)\n",
    "        \n",
    "        x = x.view(-1, self.flatten_size)        \n",
    "        \n",
    "        x = self.dense(self.dropout(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        t = self.out(x)\n",
    "        \n",
    "        return t\n",
    "    \n",
    "class ResNet_SVHN_DENSE(nn.Module):\n",
    "    def __init__(self, in_channels, out_features, depth, dense, sparsity=0.1):\n",
    "        super(ResNet_SVHN_DENSE, self).__init__()\n",
    "        \n",
    "        self.PreprocBlock = nn.Sequential(\n",
    "            nn.Conv2d(3, in_channels, kernel_size=3,padding=2),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.LBCChain = nn.Sequential(*[LBCBlock_DENSE(in_channels, out_features, sparsity=sparsity) for layer in range(depth)])\n",
    "        self.AvgPooling = nn.AvgPool2d(5,5)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten_size = in_channels * 6 * 6\n",
    "        self.dense = nn.Linear(self.flatten_size, dense)\n",
    "        self.out = nn.Linear(dense, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.PreprocBlock(x)\n",
    "        x = self.LBCChain(x)\n",
    "        x = self.AvgPooling(x)\n",
    "        \n",
    "        x = x.view(-1, self.flatten_size)        \n",
    "        \n",
    "        x = self.dense(self.dropout(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        t = self.out(x)\n",
    "        \n",
    "        return t\n",
    "    \n",
    "class ResNet_SVHN_Runner():\n",
    "    def __init__(self, dense=False, shared=False, log_interval=200):\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        self.isCuda = torch.cuda.is_available()\n",
    "        self.log_interval = log_interval\n",
    "        self.vis = visdom.Visdom(port=8889)\n",
    "        self.dense = dense\n",
    "        self.shared = shared\n",
    "        \n",
    "        if not self.vis.check_connection():\n",
    "            raise RuntimeError(\"Visdom server not running. Please run python -m visdom.server\")\n",
    "            \n",
    "    \n",
    "    def __load_data(self):\n",
    "        trainset = torchvision.datasets.SVHN(root='./data', split='train', download=True, transform=self.transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=8)\n",
    "        \n",
    "        testset = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=self.transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=8)\n",
    "        \n",
    "    \n",
    "    def compile_model(self, n_channels=16, n_weights=512, lbc_depth=40, n_dense=512, sparsity=0.9):\n",
    "        \n",
    "        self.__load_data()\n",
    "        self.start_epoch = 0\n",
    "        self.arch = [n_channels, n_weights, lbc_depth, n_dense, sparsity]\n",
    "        \n",
    "        \n",
    "        if (self.isCuda):\n",
    "            if (self.dense):\n",
    "                self.model = ResNet_SVHN_DENSE(n_channels, n_weights, lbc_depth, n_dense, sparsity).cuda()\n",
    "            else:\n",
    "                self.model = ResNet_SVHN(n_channels, n_weights, lbc_depth, n_dense, sparsity, self.shared).cuda()\n",
    "        else:\n",
    "            if (self.dense):\n",
    "                self.model = ResNet_SVHN_DENSE(n_channels, n_weights, lbc_depth, n_dense, sparsity)\n",
    "            else:\n",
    "                self.model = ResNet_SVHN(n_channels, n_weights, lbc_depth, n_dense, sparsity, self.shared)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()))\n",
    "        \n",
    "        self.trainer = create_supervised_trainer(self.model, self.optimizer, F.cross_entropy, cuda=self.isCuda)\n",
    "        self.evaluator = create_supervised_evaluator(self.model,\n",
    "                                            metrics={'accuracy': CategoricalAccuracy(),\n",
    "                                                     'loss': Loss(F.cross_entropy)},\n",
    "                                            cuda=self.isCuda)\n",
    "    \n",
    "    \n",
    "        self.best_acc = 0.0\n",
    "    \n",
    "            \n",
    "    def __create_plot_window(self, vis, xlabel, ylabel, title):\n",
    "        return vis.line(X=np.array([1]), Y=np.array([np.nan]), opts=dict(xlabel=xlabel, ylabel=ylabel, title=title))\n",
    "    \n",
    "    def __imshow(self, img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "        \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "    \n",
    "    \n",
    "    def __checkpointModel(self, epoch, current_acc):\n",
    "        self.__save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'best_prec1': self.best_acc,\n",
    "            'optimizer' : self.optimizer.state_dict(),\n",
    "            'arch': self.arch\n",
    "        }, current_acc > self.best_acc)\n",
    "    \n",
    "    def __save_checkpoint(self, state, is_best, filename='checkpoints/SVHN/SVHN_checkpoint.pth.tar'):\n",
    "        torch.save(state, filename)\n",
    "        if is_best:\n",
    "            shutil.copyfile(filename, 'checkpoints/SVHN/SVHN_model_best.pth.tar')\n",
    "            \n",
    "            \n",
    "    def resume(self, best = True, create_views = False):\n",
    "        if (best):\n",
    "            path = 'checkpoints/SVHN/SVHN_model_best.pth.tar'\n",
    "        else:\n",
    "            path = 'checkpoints/SVHN/SVHN_checkpoint.pth.tar'\n",
    "            \n",
    "        if os.path.isfile(path):\n",
    "            print(\"=> loading checkpoint '{}'\".format(path))\n",
    "            \n",
    "            checkpoint = torch.load(path)\n",
    "            self.arch = checkpoint['arch']\n",
    "            self.compile_model(*self.arch)\n",
    "            \n",
    "            \n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            \n",
    "                 \n",
    "            self.start_epoch = checkpoint['epoch']\n",
    "            self.best_acc = checkpoint['best_prec1']\n",
    "            \n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(path, checkpoint['epoch']))\n",
    "            \n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(path))\n",
    "    \n",
    "    def train(self, epochs, verbose=True, graph=False):\n",
    "        trainer = self.trainer\n",
    "        self.start_time = 0.0;\n",
    "        \n",
    "        \n",
    "        if graph:\n",
    "            self.train_loss_window = self.__create_plot_window(self.vis, '#Iterations', 'Loss', 'Training Loss')\n",
    "            self.val_accuracy_window = self.__create_plot_window(self.vis, '#Epochs', 'Accuracy', 'Validation Accuracy')\n",
    "            self.val_loss_window = self.__create_plot_window(self.vis, '#Epochs', 'Loss', 'Validation Loss')\n",
    "        \n",
    "        \n",
    "        @trainer.on(Events.EPOCH_STARTED)\n",
    "        def resume_from_epoch(engine):\n",
    "            self.start_time = time.time()\n",
    "            if (engine.state.epoch < self.start_epoch):\n",
    "                engine.state.epoch = self.start_epoch\n",
    "        \n",
    "        @trainer.on(Events.ITERATION_COMPLETED)\n",
    "        def log_training_loss(engine):\n",
    "            iter = (engine.state.iteration - 1) % len(self.trainloader) + 1\n",
    "            if iter % self.log_interval == 0:\n",
    "                if (verbose):\n",
    "                    print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f} \".format(engine.state.epoch, iter, len(self.trainloader), engine.state.output))\n",
    "                if graph:\n",
    "                    self.vis.line(X=np.array([engine.state.iteration]), Y=np.array([engine.state.output]), update='append', win=self.train_loss_window)    \n",
    "            \n",
    "        \n",
    "        @trainer.on(Events.EPOCH_COMPLETED)\n",
    "        def log_validation_results(engine):\n",
    "            self.evaluator.run(self.testloader)\n",
    "            metrics = self.evaluator.state.metrics\n",
    "            \n",
    "            avg_accuracy = metrics['accuracy']\n",
    "            avg_loss = metrics['loss']\n",
    "            if (verbose):\n",
    "                print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\".format(engine.state.epoch, avg_accuracy, avg_loss))\n",
    "            \n",
    "            if graph:\n",
    "                self.vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_accuracy]), win=self.val_accuracy_window, update='append')\n",
    "                self.vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_loss]), win=self.val_loss_window, update='append')\n",
    "    \n",
    "            self.__checkpointModel(engine.state.epoch, avg_accuracy)\n",
    "        \n",
    "            if (avg_accuracy > self.best_acc):\n",
    "                self.best_acc = avg_accuracy\n",
    "            \n",
    "            if (verbose):\n",
    "                print(\"Epoch: %d - Time: %s seconds.\" %(engine.state.epoch,(round(time.time() - self.start_time, 0))))\n",
    "        \n",
    "        trainer.run(self.trainloader, max_epochs=epochs)\n",
    "    \n",
    "    def sample(self, count):\n",
    "        dataiter = iter(self.testloader)\n",
    "        images, labels = dataiter.next()\n",
    "        \n",
    "        self.__imshow(torchvision.utils.make_grid(images[0:count,:,:,:]))\n",
    "        print('GroundTruth\\t: ', ' '.join('%5s \\t' % MNIST_CLASSES[labels[0:count][j]] for j in range(count)))\n",
    "        \n",
    "        if (self.isCuda):\n",
    "            outputs = self.model(Variable(images[0:count,:,:,:].cuda()))\n",
    "        else:\n",
    "            outputs = self.model(Variable(images[0:count,:,:,:]))\n",
    "        _, predicted = torch.max(outputs.data, 1)  \n",
    "        print('Predicted\\t: ', ' '.join('%5s \\t' % MNIST_CLASSES[predicted[j]] for j in range(count)))\n",
    "    \n",
    "    \n",
    "    def test_predictions(self):\n",
    "        predictions = []\n",
    "        for data in self.testloader:\n",
    "            images, labels = data\n",
    "            \n",
    "            if (self.isCuda):\n",
    "                outputs = self.model(Variable(images.cuda()))\n",
    "            else:\n",
    "                outputs = self.model(Variable(images))\n",
    "                                     \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            \n",
    "            numpy_pred = predicted.cpu().numpy()\n",
    "            numpy_labels = labels.cpu().numpy()\n",
    "            \n",
    "        \n",
    "            \n",
    "            entry = np.vstack((numpy_pred, numpy_labels)).T\n",
    "            \n",
    "            predictions.append(entry)\n",
    "            \n",
    "        return np.array(predictions)\n",
    "            \n",
    "                \n",
    "        \n",
    "    def accuracy(self):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in self.testloader:\n",
    "            images, labels = data\n",
    "            \n",
    "            if (self.isCuda):\n",
    "                outputs = self.model(Variable(images.cuda()))\n",
    "            else:\n",
    "                outputs = self.model(Variable(images))\n",
    "                                     \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            if (self.isCuda):\n",
    "                correct += (predicted == labels.cuda()).sum()\n",
    "            else:\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %.2f %%' % (100 * correct / total))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class fig6_runner():\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        self.sparsities = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "        self.runner = ResNet_MNIST_Runner(dense=False,shared=False,log_interval=9999)\n",
    "        \n",
    "    def run(self, lbc, epochs):\n",
    "        self.lbc = lbc\n",
    "        self.epochs = epochs;\n",
    "        bar = tqdm_notebook(self.sparsities)\n",
    "        for sparsity in bar:\n",
    "            self.runner.compile_model(8,lbc,10,32, sparsity=sparsity)\n",
    "            best_acc, val_loss = self.runner.train(epochs, verbose=False)\n",
    "            result = {\"sparsity\": sparsity, \"acc\": best_acc, \"loss\": val_loss}\n",
    "            print(result)\n",
    "            self.results.append(result)\n",
    "            \n",
    "            \n",
    "    def getResults(self):\n",
    "        print(\"Ran for %d epochs, with %d lbc filters\" % (self.epochs, self.lbc))\n",
    "        return self.results\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runner = fig6_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44496447a51342f8b862ab09f91657f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sparsity': 0.1, 'acc': 0.8085, 'loss': 0.8344033724784851}\n",
      "{'sparsity': 0.2, 'acc': 0.8271, 'loss': 0.8049701348304749}\n",
      "{'sparsity': 0.3, 'acc': 0.803, 'loss': 0.8319228510856629}\n",
      "{'sparsity': 0.4, 'acc': 0.7913, 'loss': 0.8100280796051026}\n",
      "{'sparsity': 0.5, 'acc': 0.8085, 'loss': 0.8823318679809571}\n",
      "{'sparsity': 0.6, 'acc': 0.8357, 'loss': 0.7247795224189758}\n",
      "{'sparsity': 0.7, 'acc': 0.7934, 'loss': 0.8220876407623291}\n",
      "{'sparsity': 0.8, 'acc': 0.8021, 'loss': 0.8728275770187378}\n",
      "{'sparsity': 0.9, 'acc': 0.8142, 'loss': 0.7657418704986573}\n",
      "{'sparsity': 1.0, 'acc': 0.8353, 'loss': 0.7314446989059449}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.run(lbc=32, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runner.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
